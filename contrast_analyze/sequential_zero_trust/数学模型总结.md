# 层级序贯贝叶斯零信任模型 - 数学模型总结

## 1. 模型概述

层级序贯贝叶斯零信任模型（Layer-wise Sequential Bayesian Zero-Trust Model）是一种基于统计学原理的越狱攻击检测方法。该模型不需要预先训练分类器，而是利用组件在"无害（Benign）"和"拒答（Refusal）"两种已知模式下的分布差异，动态检测输入是否为恶意的越狱攻击。

### 核心思想

将神经网络的**深度（Depth）**视为**时间轴（Time Step）**，将前向传播过程视为一个**随机过程（Stochastic Process）**。在 EOI Token 的计算过程中，每一层都在不断地对"这个输入到底是什么"进行证据积累。

---

## 2. 数学定义与假设

### 2.1 假设空间 (Hypothesis Space)

我们要区分的潜在状态 $H$（隐藏变量）：

- **$H_0$**: **Benign** (无害输入)
- **$H_1$**: **Jailbreak** (越狱/有害输入)
- **$H_{Refusal}$**: **Refusal** (拒答，作为参照基准)

**注意**：在零信任模型中，我们主要关注区分 $H_0$ 和 $H_1$，而 $H_{Refusal}$ 主要用于建立基准分布。

### 2.2 观测序列 (Observation Sequence)

定义 $\mathbf{x}^{(l)}$ 为第 $l$ 层的观测向量（即该层所有 Valid Components 的激活值集合）：

$$\mathbf{x}^{(l)} = \{ c_{l,1}, c_{l,2}, \dots, c_{l,k} \}$$

其中 $c_{l,i}$ 是第 $l$ 层第 $i$ 个关键组件的标量激活值（在方向向量上的投影）。

整个前向过程的观测流为：

$$\mathcal{X}_{1:L} = (\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(L)})$$

### 2.3 概率密度函数 (PDF)

对于每一个组件 $c_{l,i}$，我们已经离线拟合了其在不同假设下的条件概率密度：

- **$f(c_{l,i} | H_0)$**：在无害情况下的分布（使用 `benign` 数据集拟合）
- **$f(c_{l,i} | H_1)$**：在越狱情况下的分布（使用 `fail` 数据集拟合，即越狱失败/拒答）

**支持的分布类型**：
- Normal (norm)
- Student's t (t)
- Gamma (gamma)
- Lognormal (lognorm)
- Laplace (laplace)
- Beta (beta)

---

## 3. 核心数学模型

### 3.1 Step 1: 概率密度计算 (PDF Calculation)

对于每个组件 $i$ 和激活值 $x_i$，计算两个基础概率密度：

$$f_B^{(i)}(x_i) = f(x_i | H_0)$$

$$f_R^{(i)}(x_i) = f(x_i | H_1)$$

**实现细节**：
- 使用 `logpdf` 然后 `exp` 以提高数值稳定性
- 对于 Beta 分布，需要先将激活值归一化到 [0, 1] 区间
- 使用 `epsilon = 10^{-10}` 避免除零和对数域问题

### 3.2 Step 2: 原子变量计算 (Atomic Variables)

#### 2.1 已知流形概率 ($P_{known}$)

$$P_{known}^{(i)}(x_i) = 0.5 \cdot f_B^{(i)}(x_i) + 0.5 \cdot f_R^{(i)}(x_i)$$

**含义**：衡量样本是否属于已知分布（Benign 或 Refusal）。当 $P_{known}$ 很小时，说明激活值落在已知分布外（OOD）。

**权重选择**：使用 0.5/0.5 的均匀混合，假设 Benign 和 Refusal 的先验概率相等。

#### 2.2 置信权重 ($w_i$)

$$w_i = P_{known}^{(i)}(x_i)$$

**含义**：用于抑制分布外（OOD）噪声。当 $f_B, f_R \to 0$ 时，$w_i \to 0$，从而抑制 OOD 噪声。

**注意**：$w_i$ **不需要归一化**，直接使用密度值即可，因为后续的加权操作会自动缩放。

#### 2.3 原始对数似然比 ($\lambda_i$)

$$\lambda_i = \log\left(\frac{f_R^{(i)}(x_i) + \epsilon}{f_B^{(i)}(x_i) + \epsilon}\right)$$

**含义**：
- $\lambda_i > 0$：指示 Refusal（更像越狱失败/拒答）
- $\lambda_i < 0$：指示 Benign（更像无害输入）

#### 2.4 加权对数似然比 ($\tilde{\lambda}_i$)

$$\tilde{\lambda}_i = w_i \cdot \lambda_i$$

**含义**：结合置信权重的对数似然比，用于后续的一致性检测。

### 3.3 Step 3: 风险评分计算 (Risk Scores)

每一层的总风险由两个正交的评分组成：

#### 3.1 一致性得分 ($S_{cons}$) - Top-K Conflict Product

检测 Type A (感知) 与 Type B (伪装) 的解耦现象。

**算法**：
1. 对每个样本，对该层所有组件的 $\lambda_i$ 排序（降序）
2. 计算 Top-K 最大值的均值：$v_{pos} = \text{Mean}(\text{Top-K largest } \lambda_i)$
3. 计算 Bottom-K 最小值的绝对值的均值：$v_{neg} = \text{Mean}(|\text{Bottom-K smallest } \lambda_i|)$
4. 计算冲突得分：$S_{cons} = v_{pos} \times v_{neg}$

**数学直觉**：
- 如果系统中存在强烈的局部 Refusal 信号（$v_{pos}$ 大），但同时存在强烈的局部 Benign 信号（$v_{neg}$ 大），则 $S_{cons}$ 很大
- 这表示"不一致性"：系统内部有强烈的 Refusal 信号，但被 Benign 信号抵消了
- 这是**越狱攻击独有的指纹**：模型"看到了有害特征，却准备输出无害内容"

**公式**：

$$S_{cons} = \left( \frac{1}{K} \sum_{i \in \text{Top-K}} \lambda_i \right) \times \left( \frac{1}{K} \sum_{i \in \text{Bottom-K}} |\lambda_i| \right)$$

其中 $K$ 是 Top-K 参数（默认值：7）。

#### 3.2 异常得分 ($S_{ood}$)

检测 Type C (未知分布) 现象。

$$S_{ood} = \sum_{i=1}^N -\log \left( P_{known}^{(i)}(x_i) + \epsilon \right)$$

**数学直觉**：
- 当 $P_{known}$ 很大时，说明激活值落在已知分布内，$S_{ood}$ 很小
- 当 $P_{known}$ 很小时，说明激活值落在已知分布外，$S_{ood}$ 很大
- 这用于检测**完全未知的攻击模式**

### 3.4 Step 4: 总层风险 (Total Layer Risk)

$$\mathcal{R}_l = S_{cons}^{(l)} + \beta \cdot S_{ood}^{(l)}$$

其中：
- $S_{cons}^{(l)}$：第 $l$ 层的一致性得分
- $S_{ood}^{(l)}$：第 $l$ 层的异常得分
- $\beta$：OOD 得分权重（默认值：0.25）

### 3.5 Step 5: 序贯累积 (Sequential Accumulation)

**证据轨迹 (Evidence Trajectory)**：

$$\text{Trajectory}_L = \sum_{l=0}^{L} \mathcal{R}_l$$

**初始值**：$S_0 = 0$（从第 0 层开始）

**处理无有效组件的层**：如果某层没有 valid components，则该层的 $\mathcal{R}_l = 0$，累积轨迹保持不变。

---

## 4. 实现细节

### 4.1 向量化计算

**要求**：必须对 `N_samples` 进行向量化计算，禁止 Python `for` 循环。

**数据结构**：
- 输入：对于每一层 $l$，激活值形状为 `(N_samples, N_components)`
- 输出：
  - `trajectory`: `(N_samples, n_layers)` - 累积风险轨迹
  - `S_cons_all`: `(N_samples, n_layers)` - 每层的一致性得分
  - `S_ood_all`: `(N_samples, n_layers)` - 每层的异常得分
  - `R_all`: `(N_samples, n_layers)` - 每层的总风险

**注意**：不同组件可能有不同的分布类型，需要为每个组件分别计算 PDF，但可以在 `N_samples` 维度上并行计算。

### 4.2 数值稳定性

**处理策略**：
1. 使用 `logpdf` 然后 `exp` 计算 PDF
2. 在对数运算和除法中添加 `epsilon = 10^{-10}`
3. 使用 `np.clip(log_pdf, -100, None)` 避免 `exp(-inf) = 0`
4. 使用 `np.maximum(pdf, epsilon)` 确保 PDF 不为 0

### 4.3 Beta 分布特殊处理

Beta 分布需要数据归一化到 [0, 1]：

1. **归一化**：$x_{norm} = \frac{x - data_{min}}{data_{max} - data_{min}}$
2. **计算 PDF**：使用归一化后的参数计算 PDF
3. **不需要反归一化**：PDF 值本身是概率密度，不需要反归一化

### 4.4 组件激活值计算

**实时计算**：不加载预计算的激活值，而是通过 PyTorch hooks 实时计算组件在方向向量上的投影。

**支持的组件类型**：
- **Attention Head (H0-H31)**：从 attention 的 $z$ 值计算该 head 的输出投影
- **MLP**：从 MLP 输出计算投影
- **Block Residual**：从 Block 输出计算投影

**方向向量支持**：
- 1D: `(d_model,)` → 广播到所有层和所有 token
- 2D: `(n_layers, d_model)` → 广播到所有 token
- 3D: `(n_tokens, n_layers, d_model)` → 直接使用（每层每个 token 一个独立方向）

### 4.5 Token 处理策略

**多 token 聚合**：对所有 token 的 valid components 分别计算，然后聚合到同一层。

**EOI Token 定位**：使用 EOI marker 字符串定位 End-of-Instruction token 位置。

---

## 5. 输出格式

### 5.1 轨迹数据

- **形状**：`(N_samples, n_layers)`
- **含义**：每个样本在每个层的累积风险评分

### 5.2 层得分数据

- **S_cons**：`(N_samples, n_layers)` - 一致性得分
- **S_ood**：`(N_samples, n_layers)` - 异常得分
- **R_l**：`(N_samples, n_layers)` - 总层风险

### 5.3 无有效组件的层

如果某层没有 valid components：
- $S_{cons} = 0$
- $S_{ood} = 0$
- $\mathcal{R}_l = 0$

---

## 6. 模型优势

### 6.1 信息论视角

每一层神经网络不仅在处理语义信息，也在泄露关于"输入性质"的信息。该方法是在**解码（Decoding）**模型内部流动的元信息（Meta-information）。

### 6.2 时间换空间

传统的防御可能需要训练一个巨大的外部 BERT 模型（空间开销）。该方法利用了 LLM 本身深度的"时间"过程，基本不增加显存开销，只是做了一些加减法。

### 6.3 对抗鲁棒性

越狱攻击通常试图优化 Prompt 以欺骗最终的输出 Token。但是，要在**每一层**、**每一个组件**上都欺骗过概率模型，其难度是指数级上升的（几乎等同于把有害内容变成了无害内容）。

---

## 7. 实验验证

### 7.1 证据轨迹图 (Evidence Trajectory Plot)

**X轴**：层数 (Layer 0 to Layer N)

**Y轴**：累积对数似然比 $S_l$ (Evidence Score)

**线条**：
- Benign 样本的轨迹（预期：向下漂移或保持低位）
- Refusal 样本的轨迹（预期：向上漂移）
- **Jailbreak 样本的轨迹**（预期：在早期层上升，中后期震荡或持平）

**预期结果**：Jailbreak 的轨迹在早期层（Type A 组件活跃区）会猛烈上升（识别出有害），而在中后期（Type B 活跃区）可能会震荡或持平。这个"先升后平"的轨迹特征，就是零信任防御的依据。

### 7.2 层得分对比图

分别绘制 $S_{cons}$、$S_{ood}$ 和 $\mathcal{R}_l$ 的对比图，展示三种数据类型的差异。

---

## 8. 关键参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| $\beta$ | 0.25 | OOD 得分权重 |
| $K$ | 7 | Top-K Conflict Product 算法中的 K 值 |
| `batch_size` | 64 | 批处理大小 |
| `epsilon` | $10^{-10}$ | 数值稳定性常数 |

---

## 9. 参考文献与相关文档

- **关键确认点文档**：`零信任模型实现_关键确认点.md`
- **实现代码**：
  - `compute_pdfs.py` - PDF 计算
  - `layer_scores.py` - 层得分计算
  - `component_activations.py` - 组件激活值计算
  - `trajectory_compute.py` - 轨迹计算主函数
  - `main.py` - 主入口脚本

---

## 10. 数学公式总结

### 完整公式链

1. **PDF 计算**：
   $$f_B^{(i)}(x_i) = f(x_i | H_0), \quad f_R^{(i)}(x_i) = f(x_i | H_1)$$

2. **原子变量**：
   $$P_{known}^{(i)} = 0.5 \cdot f_B^{(i)} + 0.5 \cdot f_R^{(i)}$$
   $$w_i = P_{known}^{(i)}$$
   $$\lambda_i = \log\left(\frac{f_R^{(i)} + \epsilon}{f_B^{(i)} + \epsilon}\right)$$
   $$\tilde{\lambda}_i = w_i \cdot \lambda_i$$

3. **风险评分**：
   $$S_{cons} = v_{pos} \times v_{neg} = \left( \frac{1}{K} \sum_{i \in \text{Top-K}} \lambda_i \right) \times \left( \frac{1}{K} \sum_{i \in \text{Bottom-K}} |\lambda_i| \right)$$
   $$S_{ood} = \sum_{i=1}^N -\log \left( P_{known}^{(i)} + \epsilon \right)$$

4. **总层风险**：
   $$\mathcal{R}_l = S_{cons}^{(l)} + \beta \cdot S_{ood}^{(l)}$$

5. **证据轨迹**：
   $$\text{Trajectory}_L = \sum_{l=0}^{L} \mathcal{R}_l$$

---

**文档版本**：1.0  
**最后更新**：2025-01-XX  
**作者**：AI Research Engineer

